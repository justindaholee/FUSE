import h5py
import math
import os
import numpy as np
import pandas as pd
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from tensorflow import keras
from keras.callbacks import EarlyStopping
from Lineage_Library import Cell, Library
from functions import read_multiframe_tiff, extract_cells,calculate_iou, cosine_similarity

# USER INPUTS #################################################################

# Path for original cell images as .tif file
imgs_path = 'data\RFP_GFP_MIDDLE5\RFP_GFP_MIDDLE5.tif'

# Path for cell masks ouput by Cellpose as .tif file
masks_path = "data\RFP_GFP_MIDDLE5\seg_RFP_GFP_MIDDLE5.tif"

# Path for segmentation information generated by AREA as .csv file
info_path = "data\RFP_GFP_MIDDLE5\EXP_MIDDLE5_1.csv"

# Channel name to use visual feature extraction on, as a string
channel = 'RFP'

# Numerical value for max radius of which cells need for identificaiton across frames
search_radius = 100


### PART 1: Import data and Preprocessing######################################
print("IMPORTING DATA AND PREPROCESSING...")

# TODO: Check that data exists in the correct format ###############

# 1. Import data
masks = read_multiframe_tiff(masks_path)
info_df = pd.read_csv(info_path)
dir_path, base_name = os.path.split(imgs_path)

# 2. Pre-processing informational data
info_df = info_df[info_df['Channel'] == channel]
df = info_df[['Frame', 'ROI']].copy()
centroids = info_df['Centroid'].str.strip('()').str.split(', ', expand=True).astype(float)
df[['x', 'y']] = centroids


# 3. Extract cells and generate cell img database. (img name e.g., 'frame_0_cell_1')
cells_path = os.path.join(dir_path, os.path.splitext(base_name)[0] + "_cells.hdf5")
extract_cells(imgs_path, masks_path, cells_path, channel)

img_list = []
with h5py.File(cells_path, 'r') as hf:
    for key in hf.keys():
        img_list.append(hf[key][()])

x_train = np.array(img_list)
x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)
x_train, x_test = train_test_split(x_train, test_size=0.2, random_state=42)
del centroids, img_list # delete data to clear RAM

early_stop = EarlyStopping(monitor='val_loss', patience=5)

print(f"training dataset shape: {x_train.shape}")
print(f"testing dataset shape: {x_test.shape}")

# 4. Train autoencoder on the single cell images
encoder = keras.models.Sequential([
    keras.layers.Flatten(input_shape=[28, 28]),
    keras.layers.Dense(100, activation="relu"),
    keras.layers.Dense(30, activation="relu"),
])
decoder = keras.models.Sequential([
    keras.layers.Dense(100, activation="relu", input_shape=[30]),
    keras.layers.Dense(28 * 28, activation="sigmoid"),
    keras.layers.Reshape([28, 28])
])
autoencoder = keras.models.Sequential([encoder, decoder])
autoencoder.compile(loss="binary_crossentropy",
                   optimizer='adam')
history = autoencoder.fit(x_train, x_train, epochs=300,
                                  validation_data=[x_test, x_test],
                                  callbacks=[early_stop],
                                  verbose=0) 
model_path = os.path.join(dir_path, os.path.splitext(base_name)[0] + "_model.h5")
del x_train, x_test

print("PREPROCESSING COMPLETE.")


### PART 2: Frame-by-frame Pairwise Cell Labeling##############################
print("INITIATING FRAME-BY-FRAME CELL IDENTIFICATION...")

# Initialize library for tracking lineages
lib = Library(masks[0], df)

prev_mask = masks[0]
for i, mask in tqdm(enumerate(masks[1:]), total=len(masks)-1, leave=False,
                      desc="Processing Frames", unit="frame", ncols=80):
    current_frame = i + 1;
    temp_df = df[df['Frame'] == current_frame]

    for recent_cell in lib.all_recent():
        prev_mask = masks[recent_cell['frame']]

        with h5py.File(cells_path, 'r') as hf:
            key = 'frame_' + str(recent_cell['frame']) + '_cell_' + str(recent_cell['cell_id'])
            cell_img = np.array(hf[key])
            cell_img = cell_img.reshape(1, 28, 28, 1)
        recent_vec = encoder.predict(cell_img, verbose=0)

        scores = []
        for new_cell in np.unique(mask)[1:]:
            if new_cell != 0:
                x_new, y_new = temp_df[temp_df['ROI']==(new_cell-1)].iloc[0][['x', 'y']]
                distance = math.sqrt((x_new - recent_cell['x'])**2 + (y_new - recent_cell['y'])**2)
                
                if distance < search_radius:
                    with h5py.File(cells_path, 'r') as hf:
                        key = 'frame_' + str(current_frame) + '_cell_' + str(new_cell)
                        cell_img = np.array(hf[key])
                        cell_img = cell_img.reshape(1, 28, 28, 1)
                    new_vec = encoder.predict(cell_img, verbose=0)
                    
                    iou_score = calculate_iou(recent_cell['cell_id'], prev_mask, new_cell, mask)
                    visual_score = cosine_similarity(recent_vec, new_vec)
  
                    if (iou_score > 0) and (lib.is_recent_cell(current_frame, new_cell) == -1):
                        scores.append({
                            'next_cell_id': new_cell,
                            'next_cell_x': x_new,
                            'next_cell_y': y_new,
                            'lineage_id': recent_cell['lineage_id'],
                            'iou_score': iou_score,
                            'visual_score': visual_score,
                            'distance': distance
                        })
        
        lib.find_best_match(current_frame, recent_cell, scores)

print("CELL IDENTIFICATION COMPLETE.")


from pandasgui import show
show(lib.to_dataframe())